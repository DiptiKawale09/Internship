{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134de37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from selenium) (0.10.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: idna in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\vaibh\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72de102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException  #importing exception\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2479b0",
   "metadata": {},
   "source": [
    "1) Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d038dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905a9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "\n",
    "try:\n",
    "    all_rank = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "    for value in all_rank:\n",
    "        rank.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_name = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "    for value in all_name:\n",
    "        name.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    name.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_artist = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "    for value in all_artist:\n",
    "        artist.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_upload_date = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "    for value in all_upload_date:\n",
    "         upload_date.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    upload_date.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_views = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "    for value in all_views:\n",
    "        views.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    views.append(\"-\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072731fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 48, 48, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank),len(name),len(artist),len(upload_date),len(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecf5bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.48</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.28</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.82</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.45</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.11</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.05</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.62</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.52</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.05</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.99</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.92</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.46</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.09</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.95</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.89</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.89</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.80</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.75</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[44]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.72</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.67</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[47]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.60</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.58</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.56</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.53</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.53</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[52]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[53]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.48</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.48</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"Gangnam Style\"⁂[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\"Baby\"*[66]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\"Bad Romance\"[70]</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\"Charlie Bit My Finger\"‡[74]</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\"Evolution of Dance\"[77]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"Girlfriend\"‡[79][80]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"Evolution of Dance\"[77]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‡[85]</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"Evolution of Dance\"*[77]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\"Pokémon Theme Music Video\"‡[90]</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\"Myspace – The Movie\"‡[95][96]</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\"Phony Photo Booth\"‡[99]</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‡[105]</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‡*[108]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\"I/O Brush\"‡*[114]</td>\n",
       "      <td>larfus</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rank  \\\n",
       "0                                   1.   \n",
       "1                                   2.   \n",
       "2                                   3.   \n",
       "3                                   4.   \n",
       "4                                   5.   \n",
       "5                                   6.   \n",
       "6                                   7.   \n",
       "7                                   8.   \n",
       "8                                   9.   \n",
       "9                                  10.   \n",
       "10                                 11.   \n",
       "11                                 12.   \n",
       "12                                 13.   \n",
       "13                                 14.   \n",
       "14                                 15.   \n",
       "15                                 16.   \n",
       "16                                 17.   \n",
       "17                                 18.   \n",
       "18                                 19.   \n",
       "19                                 20.   \n",
       "20                                 21.   \n",
       "21                                 22.   \n",
       "22                                 23.   \n",
       "23                                 24.   \n",
       "24                                 25.   \n",
       "25                                 26.   \n",
       "26                                 27.   \n",
       "27                                 28.   \n",
       "28                                 29.   \n",
       "29                                 30.   \n",
       "30               \"Baby Shark Dance\"[6]   \n",
       "31                      \"Despacito\"[9]   \n",
       "32                 \"See You Again\"[22]   \n",
       "33                \"Gangnam Style\"⁂[31]   \n",
       "34                         \"Baby\"*[66]   \n",
       "35                   \"Bad Romance\"[70]   \n",
       "36        \"Charlie Bit My Finger\"‡[74]   \n",
       "37            \"Evolution of Dance\"[77]   \n",
       "38               \"Girlfriend\"‡[79][80]   \n",
       "39            \"Evolution of Dance\"[77]   \n",
       "40      \"Music Is My Hot Hot Sex\"‡[85]   \n",
       "41           \"Evolution of Dance\"*[77]   \n",
       "42    \"Pokémon Theme Music Video\"‡[90]   \n",
       "43      \"Myspace – The Movie\"‡[95][96]   \n",
       "44            \"Phony Photo Booth\"‡[99]   \n",
       "45   \"The Chronic of Narnia Rap\"‡[105]   \n",
       "46  \"Ronaldinho: Touch of Gold\"‡*[108]   \n",
       "47                  \"I/O Brush\"‡*[114]   \n",
       "\n",
       "                                               Name  \\\n",
       "0                             \"Baby Shark Dance\"[6]   \n",
       "1                                    \"Despacito\"[9]   \n",
       "2                        \"Johny Johny Yes Papa\"[17]   \n",
       "3                                   \"Bath Song\"[18]   \n",
       "4                                \"Shape of You\"[19]   \n",
       "5                               \"See You Again\"[22]   \n",
       "6                           \"Wheels on the Bus\"[27]   \n",
       "7                 \"Phonics Song with Two Words\"[28]   \n",
       "8                                 \"Uptown Funk\"[29]   \n",
       "9   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10                              \"Gangnam Style\"[31]   \n",
       "11   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12                             \"Dame Tu Cosita\"[37]   \n",
       "13                                     \"Axel F\"[38]   \n",
       "14                                      \"Sugar\"[39]   \n",
       "15                             \"Counting Stars\"[40]   \n",
       "16                                       \"Roar\"[41]   \n",
       "17                        \"Baa Baa Black Sheep\"[42]   \n",
       "18           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19                                      \"Sorry\"[44]   \n",
       "20                             \"Lakdi Ki Kathi\"[45]   \n",
       "21                          \"Thinking Out Loud\"[46]   \n",
       "22                                 \"Dark Horse\"[47]   \n",
       "23          \"Humpty the train on a fruits ride\"[48]   \n",
       "24                                    \"Perfect\"[49]   \n",
       "25                                 \"Let Her Go\"[50]   \n",
       "26                                      \"Faded\"[51]   \n",
       "27                             \"Girls Like You\"[52]   \n",
       "28                      \"Shree Hanuman Chalisa\"[53]   \n",
       "29                                    \"Lean On\"[54]   \n",
       "30      Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "31                                       Luis Fonsi   \n",
       "32                                      Wiz Khalifa   \n",
       "33                                              Psy   \n",
       "34                                    Justin Bieber   \n",
       "35                                        Lady Gaga   \n",
       "36                                            HDCYT   \n",
       "37                                   Judson Laipply   \n",
       "38                                      RCA Records   \n",
       "39                                   Judson Laipply   \n",
       "40                                   CLARUSBARTEL72   \n",
       "41                                   Judson Laipply   \n",
       "42                                            Smosh   \n",
       "43                                           eggtea   \n",
       "44                                        mugenized   \n",
       "45                                      youtubedude   \n",
       "46                                       Nikesoccer   \n",
       "47                                           larfus   \n",
       "\n",
       "                                               Artist              Views  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories              13.48   \n",
       "1                                          Luis Fonsi               8.28   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs               6.82   \n",
       "3                          Cocomelon - Nursery Rhymes               6.45   \n",
       "4                                          Ed Sheeran               6.11   \n",
       "5                                         Wiz Khalifa               6.05   \n",
       "6                          Cocomelon - Nursery Rhymes               5.62   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs               5.52   \n",
       "8                                         Mark Ronson               5.05   \n",
       "9                                         Miroshka TV               4.99   \n",
       "10                                        officialpsy               4.92   \n",
       "11                                         Get Movies               4.56   \n",
       "12                                      Ultra Records               4.46   \n",
       "13                                         Crazy Frog               4.09   \n",
       "14                                           Maroon 5               3.95   \n",
       "15                                        OneRepublic               3.89   \n",
       "16                                         Katy Perry               3.89   \n",
       "17                         Cocomelon - Nursery Rhymes               3.80   \n",
       "18                                            Shakira               3.75   \n",
       "19                                      Justin Bieber               3.72   \n",
       "20                                       Jingle Toons               3.71   \n",
       "21                                         Ed Sheeran               3.67   \n",
       "22                                         Katy Perry               3.60   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs               3.58   \n",
       "24                                         Ed Sheeran               3.56   \n",
       "25                                          Passenger               3.53   \n",
       "26                                        Alan Walker               3.53   \n",
       "27                                           Maroon 5               3.50   \n",
       "28                              T-Series Bhakti Sagar               3.48   \n",
       "29                               Major Lazer Official               3.48   \n",
       "30                                      7,046,700,000      June 17, 2016   \n",
       "31                                      2,993,700,000   January 12, 2017   \n",
       "32                                      2,894,000,000      April 6, 2015   \n",
       "33                                        803,700,000      July 15, 2012   \n",
       "34                                        245,400,000  February 19, 2010   \n",
       "35                                        178,400,000  November 24, 2009   \n",
       "36                                        128,900,000       May 22, 2007   \n",
       "37                                        118,900,000      April 6, 2006   \n",
       "38                                         92,600,000  February 27, 2007   \n",
       "39                                         78,400,000      April 6, 2006   \n",
       "40                                         76,600,000      April 9, 2007   \n",
       "41                                         10,600,000      April 6, 2006   \n",
       "42                                          4,300,000  November 28, 2005   \n",
       "43                                          2,700,000   January 31, 2006   \n",
       "44                                          3,400,000   December 1, 2005   \n",
       "45                                          2,300,000  December 18, 2005   \n",
       "46                                            255,000   October 21, 2005   \n",
       "47                                            247,000    October 5, 2005   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19   October 22, 2015  \n",
       "20      June 14, 2018  \n",
       "21    October 7, 2014  \n",
       "22  February 20, 2014  \n",
       "23   January 26, 2018  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26   December 3, 2015  \n",
       "27       May 31, 2018  \n",
       "28       May 10, 2011  \n",
       "29     March 22, 2015  \n",
       "30   November 2, 2020  \n",
       "31     August 4, 2017  \n",
       "32      July 10, 2017  \n",
       "33  November 24, 2012  \n",
       "34      July 16, 2010  \n",
       "35     April 14, 2010  \n",
       "36   October 25, 2009  \n",
       "37        May 2, 2009  \n",
       "38      July 17, 2008  \n",
       "39     March 15, 2008  \n",
       "40      March 1, 2008  \n",
       "41       May 19, 2006  \n",
       "42     March 12, 2006  \n",
       "43  February 18, 2006  \n",
       "44   January 21, 2006  \n",
       "45    January 9, 2006  \n",
       "46   October 31, 2005  \n",
       "47   October 29, 2005  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube = pd.DataFrame({})\n",
    "youtube['Rank'] = rank\n",
    "youtube['Name'] = name\n",
    "youtube['Artist'] = artist\n",
    "youtube['Views'] = views\n",
    "youtube['Upload Date'] = upload_date\n",
    "youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d61ca",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f5b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e85273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "close = driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3544ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_click = driver.find_element(By.XPATH,'//div[@class=\"imw-tabs international-tabs\"]/a[2]')\n",
    "link_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375149d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 PM IST',\n",
       " '9:30 PM IST',\n",
       " '9:30 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '9:30 AM IST',\n",
       " '9:30 AM IST',\n",
       " '9:30 AM IST',\n",
       " '9:30 AM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '6:30 AM IST',\n",
       " '2:00 PM IST',\n",
       " '6:30 AM IST',\n",
       " '2:00 PM IST',\n",
       " '1:30 PM IST',\n",
       " '11:30 AM IST',\n",
       " '1:30 PM IST',\n",
       " '6:30 AM IST',\n",
       " '1:30 PM IST',\n",
       " '6:30 AM IST',\n",
       " '3:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '7:30 PM IST',\n",
       " '7:30 PM IST',\n",
       " '7:30 PM IST',\n",
       " '8:00 PM IST',\n",
       " '8:00 PM IST',\n",
       " '8:00 PM IST',\n",
       " '8:00 PM IST',\n",
       " '8:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '2:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '7:30 PM IST',\n",
       " '2:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '2:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '2:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '10:00 AM IST',\n",
       " '10:00 AM IST',\n",
       " '10:00 AM IST',\n",
       " '10:00 AM IST',\n",
       " '1:30 PM IST',\n",
       " '10:00 AM IST',\n",
       " '10:00 AM IST',\n",
       " '7:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '9:00 AM IST',\n",
       " '6:30 AM IST',\n",
       " '6:30 AM IST',\n",
       " '11:00 AM IST',\n",
       " '11:00 AM IST',\n",
       " '11:00 AM IST',\n",
       " '3:00 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '9:30 AM IST',\n",
       " '6:30 PM IST',\n",
       " '6:30 PM IST',\n",
       " '6:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '6:30 PM IST',\n",
       " '6:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '3:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '1:45 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '1:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '1:45 PM IST',\n",
       " '1:45 PM IST',\n",
       " '1:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '1:45 PM IST',\n",
       " '1:30 PM IST',\n",
       " '10:00 AM IST',\n",
       " '1:30 PM IST',\n",
       " '1:45 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '10:00 AM IST',\n",
       " '1:45 PM IST',\n",
       " '10:00 AM IST',\n",
       " '1:45 PM IST',\n",
       " '10:00 AM IST',\n",
       " '9:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '1:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '1:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '1:00 PM IST',\n",
       " '7:00 AM IST',\n",
       " '1:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '1:00 PM IST',\n",
       " '7:00 AM IST',\n",
       " '7:00 AM IST',\n",
       " '1:00 PM IST',\n",
       " '1:00 PM IST',\n",
       " '12:00 PM IST',\n",
       " '12:00 PM IST',\n",
       " '12:00 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '4:30 PM IST',\n",
       " '12:39 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '1:00 PM IST',\n",
       " '8:30 AM IST',\n",
       " '1:30 PM IST',\n",
       " '1:00 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:00 PM IST',\n",
       " '1:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '1:00 PM IST',\n",
       " '1:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '1:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '7:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '3:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:00 AM IST',\n",
       " '5:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '3:30 PM IST',\n",
       " '11:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '10:30 PM IST',\n",
       " '11:30 PM IST',\n",
       " '7:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:30 PM IST',\n",
       " '7:30 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:30 PM IST',\n",
       " '7:30 PM IST']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    "\n",
    "\n",
    "try:\n",
    "    all_series = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    for value in all_series:\n",
    "        series.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    series.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_place = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]/span[2]')\n",
    "    for value in all_place:\n",
    "        place.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    place.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_date = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "    for value in all_date:\n",
    "        date.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    date.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_time = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "    for value in all_time:\n",
    "        time.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    time.append(\"-\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c74056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 210, 211, 211)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series),len(place),len(date),len(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "406f4beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Pune</td>\n",
       "      <td>19 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Dharamsala</td>\n",
       "      <td>22 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>29 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>5 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>NEW ZEALAND A TOUR OF INDIA</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>8 SEPTEMBER, 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>6 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>4 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NEW ZEALAND A TOUR OF INDIA</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>1 SEPTEMBER, 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>31 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series       Place               Date         Time\n",
       "0        ICC MENS WORLD CUP 2023        Pune   19 OCTOBER, 2023  2:00 PM IST\n",
       "1        ICC MENS WORLD CUP 2023  Dharamsala   22 OCTOBER, 2023  2:00 PM IST\n",
       "2        ICC MENS WORLD CUP 2023     Lucknow   29 OCTOBER, 2023  2:00 PM IST\n",
       "3        ICC MENS WORLD CUP 2023      Mumbai   2 NOVEMBER, 2023  2:00 PM IST\n",
       "4        ICC MENS WORLD CUP 2023     Kolkata   5 NOVEMBER, 2023  2:00 PM IST\n",
       "..                           ...         ...                ...          ...\n",
       "205  NEW ZEALAND A TOUR OF INDIA       Dubai  8 SEPTEMBER, 2022  9:30 AM IST\n",
       "206                ASIA CUP 2022       Dubai  6 SEPTEMBER, 2022  7:30 PM IST\n",
       "207                ASIA CUP 2022   Bangalore  4 SEPTEMBER, 2022  7:30 PM IST\n",
       "208  NEW ZEALAND A TOUR OF INDIA       Dubai  1 SEPTEMBER, 2022  9:30 AM IST\n",
       "209                ASIA CUP 2022       Dubai    31 AUGUST, 2022  7:30 PM IST\n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = pd.DataFrame({})\n",
    "match['Series'] = series[0:210]\n",
    "match['Place'] = place[0:210]\n",
    "match['Date'] = date[0:210]\n",
    "match['Time'] = time[0:210]\n",
    "match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf53c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d979c6",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0df6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3baf608",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_economy = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "search_economy.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "826b9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_india = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "search_india.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f5ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "search_GDP.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab7f7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp_19_20=[]\n",
    "gsdp_18_19=[]\n",
    "share_18_19=[]\n",
    "gdp_billion=[]\n",
    "\n",
    "\n",
    "try:\n",
    "    all_rank = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "    for value in all_rank:\n",
    "        rank.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_state = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "    for value in all_state:\n",
    "        state.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    state.append(\"-\")\n",
    "    \n",
    "    \n",
    "try:\n",
    "    all_gsdp_19_20 = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]')\n",
    "    for value in all_gsdp_19_20:\n",
    "        gsdp_19_20.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_19_20.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_gsdp_18_19 = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]')\n",
    "    for value in all_gsdp_18_19:\n",
    "        gsdp_18_19.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_18_19.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_share_18_19 = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]')\n",
    "    for value in all_share_18_19:\n",
    "        share_18_19.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_gdp_billion = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "    for value in all_gdp_billion:\n",
    "        gdp_billion.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    gdp_billion.append(\"-\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd5b6d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66, 66, 66, 66, 66)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank),len(state),len(gsdp_19_20),len(gsdp_18_19),len(share_18_19),len(gdp_billion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9914e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP Billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) GSDP(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.94%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
       "3     4                    Gujarat           -   1,502,899        7.96%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
       "..  ...                        ...         ...         ...          ...   \n",
       "61   29                     Sikkim      28,391      25,141        0.15%   \n",
       "62   30                   Nagaland           -      24,534        0.15%   \n",
       "63   31          Arunachal Pradesh           -      22,488        0.13%   \n",
       "64   32                    Mizoram      24,424      20,947        0.13%   \n",
       "65   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP Billion  \n",
       "0      399.921  \n",
       "1      247.629  \n",
       "2      240.726  \n",
       "3      228.290  \n",
       "4      226.806  \n",
       "..         ...  \n",
       "61      17,060  \n",
       "62           -  \n",
       "63           -  \n",
       "64      17,797  \n",
       "65           -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp = pd.DataFrame({})\n",
    "gsdp['Rank'] =rank\n",
    "gsdp['State'] = state\n",
    "gsdp['GSDP(19-20)'] = gsdp_19_20\n",
    "gsdp['GSDP(18-19)'] = gsdp_18_19\n",
    "gsdp['Share(18-19)'] = share_18_19\n",
    "gsdp['GDP Billion'] = gdp_billion\n",
    "gsdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42ce3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d5591",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4830c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\" https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52408383",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_source = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "open_source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d8d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c6c6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "urls=[]\n",
    "desc=[]\n",
    "contributer=[]\n",
    "language=[]\n",
    "language_1=[]\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    all_title = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "    for value in all_title:\n",
    "        title.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    title.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_urls = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]//a')\n",
    "    for value in all_urls:\n",
    "        urls.append(value.get_attribute(\"href\"))\n",
    "except NoSuchElementException:\n",
    "    urls.append(\"-\")\n",
    "    \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        all_desc = driver.find_elements(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        for value in all_desc:\n",
    "            desc.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        desc.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_contributer = driver.find_elements(By.XPATH,'//span[@class=\"Counter ml-1\"]')\n",
    "        for value in all_contributer:\n",
    "            contributer.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        contributer.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_language = driver.find_elements(By.XPATH,'//ul[@class=\"list-style-none\"]//li//span[1]')\n",
    "        for value in all_language:\n",
    "            language_1.append(value.text)\n",
    "        language.append(language_1)    \n",
    "    except NoSuchElementException:\n",
    "        language.append(\"-\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a3ebccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25, 23, 36, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title),len(urls),len(desc),len(contributer),len(language)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccd3eca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributer</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteByteGoHq / system-design-101</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenBMB / XAgent</td>\n",
       "      <td>An Autonomous LLM Agent for Complex Task Solving</td>\n",
       "      <td>5</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ionic-team / ionic-framework</td>\n",
       "      <td>A powerful cross-platform UI toolkit for build...</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cpacker / MemGPT</td>\n",
       "      <td>Teaching LLMs memory management for unbounded ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex313031 / thorium</td>\n",
       "      <td>Chromium fork named after radioactive element ...</td>\n",
       "      <td>468</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>9</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DarkFlippers / unleashed-firmware</td>\n",
       "      <td>Flipper Zero Unleashed Firmware</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheRealJoelmatic / RemoveAdblockThing</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td>9</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>refinedev / refine</td>\n",
       "      <td>Build your React-based CRUD applications, with...</td>\n",
       "      <td>53</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PWhiddy / PokemonRedExperiments</td>\n",
       "      <td>Playing Pokemon Red with Reinforcement Learning</td>\n",
       "      <td>292</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex313031 / Thorium-Win</td>\n",
       "      <td>Chromium fork for Windows named after radioact...</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>imteekay / programming-language-research</td>\n",
       "      <td>Programming Language Research, Applied PLT &amp; C...</td>\n",
       "      <td>7</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>devfullcycle / imersao15</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>langchain-ai / langchain</td>\n",
       "      <td>A sample app for the Retrieval-Augmented Gener...</td>\n",
       "      <td>179</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Azure-Samples / azure-search-openai-demo</td>\n",
       "      <td>This repository is for active development of t...</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>felipemotarocha / fullstackweek-store</td>\n",
       "      <td>Find and verify credentials</td>\n",
       "      <td>4</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Azure / azure-sdk-for-java</td>\n",
       "      <td>🦍 The Cloud-Native API Gateway</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trufflesecurity / trufflehog</td>\n",
       "      <td>Authentication for the Web.</td>\n",
       "      <td>4</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kong / kong</td>\n",
       "      <td>The best way to start a full-stack, typesafe N...</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nextauthjs / next-auth</td>\n",
       "      <td>Three.js-based implementation of the 3D Gaussi...</td>\n",
       "      <td>3</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3-oss / create-t3-app</td>\n",
       "      <td>game of active directory</td>\n",
       "      <td></td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mkkellogg / GaussianSplats3D</td>\n",
       "      <td>⛅️ Home to Wrangler, the CLI for Cloudflare Wo...</td>\n",
       "      <td>1,711</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Orange-Cyberdefense / GOAD</td>\n",
       "      <td>Node.js JavaScript runtime ✨🐢🚀✨</td>\n",
       "      <td>49</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0           ByteByteGoHq / system-design-101   \n",
       "1                           OpenBMB / XAgent   \n",
       "2               ionic-team / ionic-framework   \n",
       "3                           cpacker / MemGPT   \n",
       "4                       Alex313031 / thorium   \n",
       "5       cloudcommunity / Free-Certifications   \n",
       "6          DarkFlippers / unleashed-firmware   \n",
       "7      TheRealJoelmatic / RemoveAdblockThing   \n",
       "8                         refinedev / refine   \n",
       "9            PWhiddy / PokemonRedExperiments   \n",
       "10                  Alex313031 / Thorium-Win   \n",
       "11  imteekay / programming-language-research   \n",
       "12                  devfullcycle / imersao15   \n",
       "13                  langchain-ai / langchain   \n",
       "14  Azure-Samples / azure-search-openai-demo   \n",
       "15     felipemotarocha / fullstackweek-store   \n",
       "16                Azure / azure-sdk-for-java   \n",
       "17              trufflesecurity / trufflehog   \n",
       "18                               Kong / kong   \n",
       "19                    nextauthjs / next-auth   \n",
       "20                    t3-oss / create-t3-app   \n",
       "21              mkkellogg / GaussianSplats3D   \n",
       "22                Orange-Cyberdefense / GOAD   \n",
       "\n",
       "                                          Description Contributer  \\\n",
       "0   Explain complex systems using visuals and simp...               \n",
       "1    An Autonomous LLM Agent for Complex Task Solving           5   \n",
       "2   A powerful cross-platform UI toolkit for build...               \n",
       "3   Teaching LLMs memory management for unbounded ...           9   \n",
       "4   Chromium fork named after radioactive element ...         468   \n",
       "5    A curated list of free courses & certifications.           9   \n",
       "6                     Flipper Zero Unleashed Firmware               \n",
       "7   Removes The \"Ad blocker are not allowed on You...           9   \n",
       "8   Build your React-based CRUD applications, with...          53   \n",
       "9     Playing Pokemon Red with Reinforcement Learning         292   \n",
       "10  Chromium fork for Windows named after radioact...               \n",
       "11  Programming Language Research, Applied PLT & C...           7   \n",
       "12  ⚡ Building applications with LLMs through comp...               \n",
       "13  A sample app for the Retrieval-Augmented Gener...         179   \n",
       "14  This repository is for active development of t...               \n",
       "15                        Find and verify credentials           4   \n",
       "16                     🦍 The Cloud-Native API Gateway               \n",
       "17                        Authentication for the Web.           4   \n",
       "18  The best way to start a full-stack, typesafe N...               \n",
       "19  Three.js-based implementation of the 3D Gaussi...           3   \n",
       "20                           game of active directory               \n",
       "21  ⛅️ Home to Wrangler, the CLI for Cloudflare Wo...       1,711   \n",
       "22                    Node.js JavaScript runtime ✨🐢🚀✨          49   \n",
       "\n",
       "                                             Language  \n",
       "0   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "1   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "2   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "3   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "4   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "5   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "6   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "7   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "8   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "9   [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "10  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "11  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "12  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "13  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "14  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "15  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "16  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "17  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "18  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "19  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "20  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "21  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "22  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = pd.DataFrame({})\n",
    "github['Title'] =title[0:23]\n",
    "github['Description'] = desc[0:23]\n",
    "github['Contributer'] = contributer[0:23]\n",
    "github['Language'] = language[0:23]\n",
    "\n",
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "953e812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d9bc8",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ab2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78f8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11412206",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_click = driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button')\n",
    "chart_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d548d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot100_click = driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "hot100_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae42c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[]\n",
    "artist_name=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "weeks_on_board=[]\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    all_song_name = driver.find_elements(By.XPATH,' //h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\"]')\n",
    "    for value in all_song_name:                   \n",
    "        song_name.append(value.text)\n",
    "        \n",
    "    #from 2 nd song name\n",
    "    \n",
    "    all_song_name = driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for value in all_song_name:                   \n",
    "        song_name.append(value.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    song_name.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_artist_name = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "    for value in all_artist_name:                   \n",
    "        artist_name.append(value.text)\n",
    "        \n",
    "    #from 2 nd song name\n",
    "    \n",
    "    all_artist_name = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for value in all_artist_name:                   \n",
    "        artist_name.append(value.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    artist_name.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_last_week_rank = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "    for value in all_last_week_rank:                   \n",
    "        last_week_rank.append(value.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    last_week_rank.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_peak_rank = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "    for value in all_peak_rank:                   \n",
    "        peak_rank.append(value.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    peak_rank.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_weeks_on_board = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "    for value in all_weeks_on_board:                   \n",
    "        weeks_on_board.append(value.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    weeks_on_board.append(\"-\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b91e04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_name),len(artist_name),len(last_week_rank),len(peak_rank),len(weeks_on_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854608b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Weal Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First Person Shooter</td>\n",
       "      <td>Drake Featuring J. Cole</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDGAF</td>\n",
       "      <td>Drake Featuring Yeat</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake Featuring 21 Savage</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>God Gave Me A Girl</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Y Lloro</td>\n",
       "      <td>Junior H</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Telekinesis</td>\n",
       "      <td>Travis Scott Featuring SZA &amp; Future</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Seven</td>\n",
       "      <td>Jung Kook Featuring Latto</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Stars Like Confetti</td>\n",
       "      <td>Dustin Lynch</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song Name                          Artist Name Last Weal Rank  \\\n",
       "0   First Person Shooter              Drake Featuring J. Cole              -   \n",
       "1                  IDGAF                 Drake Featuring Yeat              -   \n",
       "2         Virginia Beach                                Drake              -   \n",
       "3     Paint The Town Red                             Doja Cat              1   \n",
       "4        Calling For You            Drake Featuring 21 Savage              -   \n",
       "..                   ...                                  ...            ...   \n",
       "95    God Gave Me A Girl                    Russell Dickerson             90   \n",
       "96               Y Lloro                             Junior H              -   \n",
       "97           Telekinesis  Travis Scott Featuring SZA & Future             72   \n",
       "98                 Seven            Jung Kook Featuring Latto             57   \n",
       "99   Stars Like Confetti                         Dustin Lynch             89   \n",
       "\n",
       "   Peak Rank Weeks on Board  \n",
       "0          1              1  \n",
       "1          2              1  \n",
       "2          3              1  \n",
       "3          1             10  \n",
       "4          5              1  \n",
       "..       ...            ...  \n",
       "95        90              2  \n",
       "96        97              1  \n",
       "97        26             11  \n",
       "98         1             13  \n",
       "99        89              2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard = pd.DataFrame({})\n",
    "billboard['Song Name'] =song_name\n",
    "billboard['Artist Name'] = artist_name\n",
    "billboard['Last Weal Rank'] = last_week_rank\n",
    "billboard['Peak Rank'] = peak_rank\n",
    "billboard['Weeks on Board'] = weeks_on_board\n",
    "\n",
    "billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ee908",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371198da",
   "metadata": {},
   "source": [
    "6) Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "    Url-https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bffbb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f582833",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publisher=[]\n",
    "gener=[]\n",
    "\n",
    "\n",
    "try:\n",
    "    all_book_name = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for value in all_book_name:                   \n",
    "        book_name.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    book_name.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_author_name = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for value in all_author_name:                   \n",
    "        author_name.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    author_name.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_volumes_sold = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for value in all_volumes_sold:                   \n",
    "        volumes_sold.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_publisher = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for value in all_publisher:                   \n",
    "        publisher.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    publisher.append(\"-\")\n",
    "\n",
    "try:\n",
    "    all_gener = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for value in all_gener:                   \n",
    "        gener.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    gener.append(\"-\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d6650c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_name),len(author_name),len(volumes_sold),len(publisher),len(gener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45db2bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Books Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Gener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Transworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Orion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Books Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher            Gener  \n",
       "0    5,094,805       Transworld       Transworld  \n",
       "1    4,475,152       Bloomsbury       Bloomsbury  \n",
       "2    4,200,654       Bloomsbury       Bloomsbury  \n",
       "3    4,179,479       Bloomsbury       Bloomsbury  \n",
       "4    3,758,936     Random House     Random House  \n",
       "..         ...              ...              ...  \n",
       "95     807,311     Random House     Random House  \n",
       "96     794,201          Penguin          Penguin  \n",
       "97     792,187  Scholastic Ltd.  Scholastic Ltd.  \n",
       "98     791,507            Orion            Orion  \n",
       "99     791,095          Penguin          Penguin  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestbooks = pd.DataFrame({})\n",
    "bestbooks['Books Name'] =book_name\n",
    "bestbooks['Author Name'] = author_name\n",
    "bestbooks['Volume Sold'] = volumes_sold\n",
    "bestbooks['Publisher'] = publisher\n",
    "bestbooks['Gener'] = gener\n",
    "\n",
    "bestbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7002603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f557f",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d2e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\" https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc8885b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "year_span=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "\n",
    "try:\n",
    "    all_name = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for value in all_name:                   \n",
    "        name.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    name.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_year_span = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "    for value in all_year_span:                   \n",
    "        year_span.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    year_span.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_genre = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "    for value in all_genre:                   \n",
    "        genre.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_run_time = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "    for value in all_run_time:                   \n",
    "        run_time.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    run_time.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_ratings = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')\n",
    "    for value in all_ratings:                   \n",
    "        ratings.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    ratings.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    all_votes = driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "    for value in all_votes:                   \n",
    "        votes.append(value.text)\n",
    "except NoSuchElementException:\n",
    "    votes.append(\"-\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf42088b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name),len(year_span),len(genre),len(run_time),len(ratings),len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be4f9d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,213,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,283,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,050,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>270,253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Series Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,213,628  \n",
       "1    51 min     8.7  1,283,377  \n",
       "2    44 min     8.1  1,050,461  \n",
       "3    60 min     7.5    308,644  \n",
       "4    43 min     7.6    267,582  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,961  \n",
       "96   50 min     7.8     65,033  \n",
       "97   42 min     8.1    211,945  \n",
       "98   45 min       7     44,115  \n",
       "99  572 min     8.6    270,253  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_watched_tv_series = pd.DataFrame({})\n",
    "most_watched_tv_series['Series Name'] =name\n",
    "most_watched_tv_series['Year Span'] = year_span\n",
    "most_watched_tv_series['Genre'] = genre\n",
    "most_watched_tv_series['Run Time'] = run_time\n",
    "most_watched_tv_series['Ratings'] = ratings\n",
    "most_watched_tv_series['Votes'] = votes\n",
    "\n",
    "most_watched_tv_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9d68a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a48e1",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcd902e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "047322e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "all_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67a14cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name=[]\n",
    "data_type=[]\n",
    "task=[]\n",
    "atrribute_type=[]\n",
    "no_of_instances=[]\n",
    "no_of_atrribute=[]\n",
    "year=[]\n",
    "urls=[]\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    all_urls = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for value in all_urls:\n",
    "        urls.append(value.get_attribute(\"href\"))\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        # scrap data from next button\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "len(urls)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffd08a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        all_dataset_name = driver.find_elements(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "        for value in all_dataset_name:\n",
    "            dataset_name.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        dataset_name.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_data_type = driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[1]/p')\n",
    "        for value in all_data_type:\n",
    "            data_type.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        data_type.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_task = driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[3]/p')\n",
    "        for value in all_task:\n",
    "            task.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        task.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_atrribute_type = driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[4]/p')\n",
    "        for value in all_atrribute_type:\n",
    "            atrribute_type.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        atrribute_type.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_no_of_instances = driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[5]/p')\n",
    "        for value in all_no_of_instances:\n",
    "            no_of_instances.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        no_of_instances.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_no_of_atrribute = driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[6]/p')\n",
    "        for value in all_no_of_atrribute:\n",
    "            no_of_atrribute.append(value.text)\n",
    "    except NoSuchElementException:\n",
    "        no_of_atrribute.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        all_year = driver.find_elements(By.XPATH,'//h2[@class=\"text-sm text-primary-content\"]')\n",
    "        for value in all_year:\n",
    "            year.append(value.text[-4:])\n",
    "    except NoSuchElementException:\n",
    "        year.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80162828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100, 100, 88)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_name),len(data_type),len(task),len(atrribute_type),len(no_of_instances),len(no_of_atrribute),len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a1115cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Atrribute Type</th>\n",
       "      <th>No Of Instances</th>\n",
       "      <th>No Of Atrribute</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>649</td>\n",
       "      <td>-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thyroid Disease</td>\n",
       "      <td>Multivariate, Domain-Theory</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>7200</td>\n",
       "      <td>5</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>4601</td>\n",
       "      <td>57</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Predict students' dropout and academic success</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>4424</td>\n",
       "      <td>36</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Online Retail</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>541909</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Parkinsons</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>197</td>\n",
       "      <td>-</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>US Census Data (1990)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>2458285</td>\n",
       "      <td>-</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Multiple Features</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>2000</td>\n",
       "      <td>-</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Balloons</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>16</td>\n",
       "      <td>-</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Online News Popularity</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>39797</td>\n",
       "      <td>-</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Dataset Name  \\\n",
       "0                              Student Performance   \n",
       "1                                  Thyroid Disease   \n",
       "2                                         Spambase   \n",
       "3   Predict students' dropout and academic success   \n",
       "4                                    Online Retail   \n",
       "..                                             ...   \n",
       "83                                      Parkinsons   \n",
       "84                           US Census Data (1990)   \n",
       "85                               Multiple Features   \n",
       "86                                        Balloons   \n",
       "87                          Online News Popularity   \n",
       "\n",
       "                                Data Type                        Task  \\\n",
       "0                            Multivariate  Classification, Regression   \n",
       "1             Multivariate, Domain-Theory              Classification   \n",
       "2                            Multivariate              Classification   \n",
       "3                                 Tabular              Classification   \n",
       "4   Multivariate, Sequential, Time-Series  Classification, Clustering   \n",
       "..                                    ...                         ...   \n",
       "83                           Multivariate              Classification   \n",
       "84                           Multivariate                  Clustering   \n",
       "85                           Multivariate              Classification   \n",
       "86                           Multivariate              Classification   \n",
       "87                           Multivariate  Classification, Regression   \n",
       "\n",
       "       Atrribute Type No Of Instances No Of Atrribute  year  \n",
       "0             Integer             649               -  2014  \n",
       "1   Categorical, Real            7200               5  1986  \n",
       "2       Integer, Real            4601              57  1999  \n",
       "3                   -            4424              36  2021  \n",
       "4       Integer, Real          541909               6  2015  \n",
       "..                ...             ...             ...   ...  \n",
       "83               Real             197               -  2022  \n",
       "84        Categorical         2458285               -  2021  \n",
       "85      Integer, Real            2000               -  2022  \n",
       "86        Categorical              16               -  1988  \n",
       "87      Integer, Real           39797               -  1992  \n",
       "\n",
       "[88 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame({})\n",
    "datasets['Dataset Name'] =dataset_name[0:88]\n",
    "datasets['Data Type'] = data_type[0:88]\n",
    "datasets['Task'] = task[0:88]\n",
    "datasets['Atrribute Type'] = atrribute_type[0:88]\n",
    "datasets['No Of Instances'] = no_of_instances[0:88]\n",
    "datasets['No Of Atrribute'] = no_of_atrribute[0:88]\n",
    "datasets['year'] = year[0:88]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0d63dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816cd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212168da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
