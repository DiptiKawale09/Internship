{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a079c87",
   "metadata": {},
   "source": [
    "# Web Scraping - BeautifulSoup Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2bc86",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "page= requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "#empty list\n",
    "header_list = []\n",
    "\n",
    "# Loop \n",
    "for header in headers:\n",
    "    header_text = header.get_text(\" \").strip().replace('\\n', '') \n",
    "    header_list.append(header_text)\n",
    "#print(header_list)\n",
    "df = pd.DataFrame({'titles':header_list})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87b310",
   "metadata": {},
   "source": [
    "2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98c26376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0                1                 2\n",
      "0                           Name           Tenure            Tenure\n",
      "1                           Name       Start Date      Closing date\n",
      "2            Dr. Rajendra Prasad  26 January 1950       13 May 1962\n",
      "3   Dr. Sarvepalli Radhakrishnan      13 May 1962       13 May 1967\n",
      "4              Dr. Zakir Hussain      13 May 1967        3 May 1969\n",
      "5        Varahagiri Venkata Giri       3 May 1969      20 July 1969\n",
      "6        Varahagiri Venkata Giri   24 August 1969    24 August 1974\n",
      "7           Fakhruddin Ali Ahmed   24 August 1974  11 February 1977\n",
      "8           Neelam Sanjiva Reddy     25 July 1977      25 July 1982\n",
      "9               Giani Zali Singh     25 July 1982      25 July 1987\n",
      "10        Ramaswamy Venkataraman     25 July 1987      25 July 1992\n",
      "11          Shankar Dayal Sharma     25 July 1992      25 July 1997\n",
      "12      Kocheril Raman Narayanan     25 July 1997      25 July 2002\n",
      "13        Dr. A.P.J. Abdul Kalam     25 July 2002      25 July 2007\n",
      "14                Pratibha Patil     25 July 2007      25 July 2012\n",
      "15              Pranab Mukherjee     25 July 2012      25 July 2017\n",
      "16          Shri Ram Nath Kovind     25 July 2017      21 July 2022\n",
      "17                Draupadi Murmu     21 July 2022           Working\n"
     ]
    }
   ],
   "source": [
    "page= requests.get('https://currentaffairs.adda247.com/list-of-presidents-of-india/')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "table = soup.find('table')\n",
    "df3 = pd.read_html(str(table))[0]\n",
    "#df3.columns = ['Name','www','rfthh']\n",
    "print(df3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df914577",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcf79b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank             Team  Matches  Points  Rating\n",
      "0     1    Australia AUS       27    3112     115\n",
      "1     2     Pakistan PAK       27    3102     115\n",
      "2     3        India IND       40    4558     114\n",
      "3     4      England ENG       28    2942     105\n",
      "4     5  South Africa SA       23    2386     104\n",
      "5     6   New Zealand NZ       31    3110     100\n",
      "6     7   Bangladesh BAN       33    3107      94\n",
      "7     8     Sri Lanka SL       37    3448      93\n",
      "8     9  Afghanistan AFG       21    1687      80\n",
      "9    10   West Indies WI       38    2582      68\n"
     ]
    }
   ],
   "source": [
    "#top 10 ODI teams in men’s cricket along with the records for matches, points and rating\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "df3 = pd.read_html(str(table))[0]\n",
    "df3.columns = ['Rank', 'Team', 'Matches', 'Points', 'Rating']\n",
    "print(df3.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa2c7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Player Name Team  Rating\n",
      "0             Babar Azam  PAK     863\n",
      "1           Shubman Gill  IND     759\n",
      "2  Rassie van der Dussen   SA     745\n",
      "3           David Warner  AUS     739\n",
      "4            Imam-ul-Haq  PAK     735\n",
      "5           Harry Tector  IRE     726\n",
      "6        Quinton de Kock   SA     721\n",
      "7            Virat Kohli  IND     715\n",
      "8           Rohit Sharma  IND     707\n",
      "9           Fakhar Zaman  PAK     705\n"
     ]
    }
   ],
   "source": [
    "#Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping the data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Cleaning the data\n",
    "df.drop(['Pos', 'Career Best Rating'], axis=1, inplace=True)\n",
    "df.columns = [ 'Player Name', 'Team', 'Rating']\n",
    "\n",
    "# Displaying the data\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f2ef869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Player Name Team  Rating\n",
      "0    Josh Hazlewood  AUS     692\n",
      "1    Mitchell Starc  AUS     666\n",
      "2       Trent Boult   NZ     666\n",
      "3        Adam Zampa  AUS     663\n",
      "4        Matt Henry   NZ     658\n",
      "5  Mujeeb Ur Rahman  AFG     657\n",
      "6     Kuldeep Yadav  IND     656\n",
      "7       Rashid Khan  AFG     655\n",
      "8    Mohammed Siraj  IND     643\n",
      "9    Shaheen Afridi  PAK     635\n"
     ]
    }
   ],
   "source": [
    "#Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping the data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Cleaning the data\n",
    "df.drop(['Pos', 'Career Best Rating'], axis=1, inplace=True)\n",
    "df.columns = [ 'Player Name', 'Team', 'Rating']\n",
    "\n",
    "# Displaying the data\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0af83",
   "metadata": {},
   "source": [
    "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7cb0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank             Team  Matches  Points  Rating\n",
      "0     1    Australia AUS       26    4290     165\n",
      "1     2      England ENG       31    3875     125\n",
      "2     3  South Africa SA       26    3098     119\n",
      "3     4        India IND       30    3039     101\n",
      "4     5   New Zealand NZ       28    2688      96\n",
      "5     6   West Indies WI       29    2743      95\n",
      "6     7   Bangladesh BAN       17    1284      76\n",
      "7     8     Sri Lanka SL       12     820      68\n",
      "8     9     Thailand THA       13     883      68\n",
      "9    10     Pakistan PAK       27    1678      62\n"
     ]
    }
   ],
   "source": [
    "#Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "df3 = pd.read_html(str(table))[0]\n",
    "df3.columns = ['Rank', 'Team', 'Matches', 'Points', 'Rating']\n",
    "print(df3.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1e9d2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Player Name Team  Rating\n",
      "0  Natalie Sciver-Brunt  ENG     801\n",
      "1           Beth Mooney  AUS     751\n",
      "2   Chamari Athapaththu   SL     743\n",
      "3       Laura Wolvaardt   SA     708\n",
      "4       Smriti Mandhana  IND     708\n",
      "5          Alyssa Healy  AUS     702\n",
      "6      Harmanpreet Kaur  IND     694\n",
      "7          Ellyse Perry  AUS     686\n",
      "8           Meg Lanning  AUS     682\n",
      "9       Stafanie Taylor   WI     618\n"
     ]
    }
   ],
   "source": [
    "# Top 10 women’s ODI Batting players along with the records of their team and rating. \n",
    "url ='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping the data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Cleaning the data\n",
    "df.drop(['Pos', 'Career Best Rating'], axis=1, inplace=True)\n",
    "df.columns = [ 'Player Name', 'Team', 'Rating']\n",
    "\n",
    "# Displaying the data\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98de7019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Player Name Team  Rating\n",
      "0  Natalie Sciver-Brunt  ENG     398\n",
      "1      Ashleigh Gardner  AUS     389\n",
      "2       Hayley Matthews   WI     382\n",
      "3        Marizanne Kapp   SA     362\n",
      "4          Ellyse Perry  AUS     329\n",
      "5           Amelia Kerr   NZ     328\n",
      "6         Deepti Sharma  IND     312\n",
      "7         Jess Jonassen  AUS     241\n",
      "8         Sophie Devine   NZ     233\n",
      "9              Nida Dar  PAK     217\n"
     ]
    }
   ],
   "source": [
    "#Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping the data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Cleaning the data\n",
    "df.drop(['Pos', 'Career Best Rating'], axis=1, inplace=True)\n",
    "df.columns = [ 'Player Name', 'Team', 'Rating']\n",
    "\n",
    "# Displaying the data\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee1bb7",
   "metadata": {},
   "source": [
    "5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame-\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab0e9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Headline Time  \\\n",
      "0   Dow sheds nearly 300 points Friday, S&P 500 an...  N/A   \n",
      "1   U.S. ambassador to Russia visits jailed report...  N/A   \n",
      "2   Poland, Hungary, Slovakia to introduce own ban...  N/A   \n",
      "3   Senators ask Pentagon for answers on SpaceX’s ...  N/A   \n",
      "4   UK designates Wagner Group as terrorists; Russ...  N/A   \n",
      "5   With outlaws for allies, is Russia becoming an...  N/A   \n",
      "6   Shipping giant Maersk unveils world's first ve...  N/A   \n",
      "7   Major UN report offers damning assessment of t...  N/A   \n",
      "8   Countries are refinancing debt into ocean cons...  N/A   \n",
      "9   We have to work with the private sector: The N...  N/A   \n",
      "10  $700 billion a year is needed to reverse the d...  N/A   \n",
      "11  Thai hospitality magnate is 'very optimistic' ...  N/A   \n",
      "12  The Middle East has become the 'hub for the wo...  N/A   \n",
      "13  ASEAN ‘at a loss for ideas’ on how to handle M...  N/A   \n",
      "14  Our estates have distinguished themselves: Mya...  N/A   \n",
      "15  Philippines' Globe Telecom CEO on how AI can b...  N/A   \n",
      "16  An Italian island is letting foreigners live r...  N/A   \n",
      "17  Years in the making, Venice approves a tax on ...  N/A   \n",
      "18  Watch a hotel room transform into a $62,000 su...  N/A   \n",
      "19  Where to stay in India? Here are 8 former pala...  N/A   \n",
      "20  Wall, what wall? Two detained after leveling p...  N/A   \n",
      "21  4 things the world's longest-living people do ...  N/A   \n",
      "22  How Olipop's founders started a soda brand bri...  N/A   \n",
      "23  U.S. states where property taxes are highest—N...  N/A   \n",
      "24  We built Olipop: A $20 million a month soda co...  N/A   \n",
      "25  The No. 1 thing successful parents who raise t...  N/A   \n",
      "\n",
      "                                            News Link  \n",
      "0   https://www.cnbc.com/2023/09/14/stock-futures-...  \n",
      "1   https://www.cnbc.com/2023/09/16/us-ambassador-...  \n",
      "2   https://www.cnbc.com/2023/09/16/poland-hungary...  \n",
      "3   https://www.cnbc.com/2023/09/15/spacex-starlin...  \n",
      "4   https://www.cnbc.com/2023/09/15/live-updates-l...  \n",
      "5   https://www.cnbc.com/2023/09/15/is-russia-a-ro...  \n",
      "6   https://www.cnbc.com/2023/09/14/shipping-giant...  \n",
      "7   https://www.cnbc.com/2023/09/08/climate-un-rep...  \n",
      "8   https://www.cnbc.com/video/2023/09/14/countrie...  \n",
      "9   https://www.cnbc.com/video/2023/09/14/we-have-...  \n",
      "10  https://www.cnbc.com/video/2023/09/14/700-bill...  \n",
      "11  https://www.cnbc.com/2023/09/13/thai-hospitali...  \n",
      "12  https://www.cnbc.com/video/2023/09/11/middle-e...  \n",
      "13  https://www.cnbc.com/2023/09/05/asean-at-a-los...  \n",
      "14  https://www.cnbc.com/video/2023/09/11/yoma-str...  \n",
      "15  https://www.cnbc.com/video/2023/09/04/philippi...  \n",
      "16  https://www.cnbc.com/2023/09/15/digital-nomads...  \n",
      "17  https://www.cnbc.com/2023/09/13/new-tax-to-vis...  \n",
      "18  https://www.cnbc.com/video/2023/09/11/watch-a-...  \n",
      "19  https://www.cnbc.com/2023/09/08/where-to-stay-...  \n",
      "20  https://www.cnbc.com/2023/09/07/great-wall-of-...  \n",
      "21  https://www.cnbc.com/2023/09/16/4-things-the-w...  \n",
      "22  https://www.cnbc.com/2023/09/16/how-olipops-fo...  \n",
      "23  https://www.cnbc.com/2023/09/16/us-states-wher...  \n",
      "24  https://www.cnbc.com/video/2023/09/16/we-built...  \n",
      "25  https://www.cnbc.com/2023/09/16/the-no-1-paren...  \n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "headlines = []\n",
    "times = []\n",
    "news_links = []\n",
    "\n",
    "for data in soup.find_all(\"div\", class_=\"Card-titleContainer\"):\n",
    "    headline = data.find(\"a\").text.strip()\n",
    "    time_element = data.find(\"time\")\n",
    "    if time_element is not None:\n",
    "        time = time_element.text.strip()\n",
    "    else:\n",
    "        time = \"N/A\"\n",
    "    news_link = data.find(\"a\")[\"href\"]\n",
    "    headlines.append(headline)\n",
    "    times.append(time)\n",
    "    news_links.append(news_link)\n",
    "    # print(data)\n",
    "df = pd.DataFrame({\"Headline\": headlines,\"Time\": times, \"News Link\": news_links})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee18e0",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame-\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c7853c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Paper Title  \\\n",
      "0                                    Reward is enough   \n",
      "1   Explanation in artificial intelligence: Insigh...   \n",
      "2              Creativity and artificial intelligence   \n",
      "3   Conflict-based search for optimal multi-agent ...   \n",
      "4   Knowledge graphs as tools for explainable mach...   \n",
      "5   Law and logic: A review from an argumentation ...   \n",
      "6   Between MDPs and semi-MDPs: A framework for te...   \n",
      "7   Explaining individual predictions when feature...   \n",
      "8       Multiple object tracking: A literature review   \n",
      "9   A survey of inverse reinforcement learning: Ch...   \n",
      "10  Evaluating XAI: A comparison of rule-based and...   \n",
      "11  Explainable AI tools for legal reasoning about...   \n",
      "12            Hard choices in artificial intelligence   \n",
      "13  Assessing the communication gap between AI mod...   \n",
      "14  Explaining black-box classifiers using post-ho...   \n",
      "15  The Hanabi challenge: A new frontier for AI re...   \n",
      "16              Wrappers for feature subset selection   \n",
      "17  Artificial cognition for social human–robot in...   \n",
      "18  A review of possible effects of cognitive bias...   \n",
      "19  The multifaceted impact of Ada Lovelace in the...   \n",
      "20  Robot ethics: Mapping the issues for a mechani...   \n",
      "21          Reward (Mis)design for autonomous driving   \n",
      "22  Planning and acting in partially observable st...   \n",
      "23  What do we want from Explainable Artificial In...   \n",
      "\n",
      "                                              Authors  Published Date  \\\n",
      "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
      "1                                         Tim Miller    February 2019   \n",
      "2                                  Margaret A. Boden      August 1998   \n",
      "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
      "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
      "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
      "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
      "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
      "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
      "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
      "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
      "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
      "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
      "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
      "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
      "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
      "16                        Ron Kohavi, George H. John    December 1997   \n",
      "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
      "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
      "19                            Luigia Carlucci Aiello        June 2016   \n",
      "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
      "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
      "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
      "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
      "\n",
      "                                            Paper URL  \n",
      "0   https://www.sciencedirect.com/science/article/...  \n",
      "1   https://www.sciencedirect.com/science/article/...  \n",
      "2   https://www.sciencedirect.com/science/article/...  \n",
      "3   https://www.sciencedirect.com/science/article/...  \n",
      "4   https://www.sciencedirect.com/science/article/...  \n",
      "5   https://www.sciencedirect.com/science/article/...  \n",
      "6   https://www.sciencedirect.com/science/article/...  \n",
      "7   https://www.sciencedirect.com/science/article/...  \n",
      "8   https://www.sciencedirect.com/science/article/...  \n",
      "9   https://www.sciencedirect.com/science/article/...  \n",
      "10  https://www.sciencedirect.com/science/article/...  \n",
      "11  https://www.sciencedirect.com/science/article/...  \n",
      "12  https://www.sciencedirect.com/science/article/...  \n",
      "13  https://www.sciencedirect.com/science/article/...  \n",
      "14  https://www.sciencedirect.com/science/article/...  \n",
      "15  https://www.sciencedirect.com/science/article/...  \n",
      "16  https://www.sciencedirect.com/science/article/...  \n",
      "17  https://www.sciencedirect.com/science/article/...  \n",
      "18  https://www.sciencedirect.com/science/article/...  \n",
      "19  https://www.sciencedirect.com/science/article/...  \n",
      "20  https://www.sciencedirect.com/science/article/...  \n",
      "21  https://www.sciencedirect.com/science/article/...  \n",
      "22  https://www.sciencedirect.com/science/article/...  \n",
      "23  https://www.sciencedirect.com/science/article/...  \n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "dates = []\n",
    "urls = []\n",
    "\n",
    "for t1 in soup.find_all(\"h2\", class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    titles.append(t1.text)\n",
    "for a1 in soup.find_all(\"span\", class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(a1.text)\n",
    "for d1 in soup.find_all(\"span\", class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    dates.append(d1.text)\n",
    "for u1 in soup.find_all(\"a\", class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    urls.append(u1[\"href\"])\n",
    "\n",
    "df = pd.DataFrame({\"Paper Title\": titles, \"Authors\": authors, \"Published Date\": dates, \"Paper URL\": urls})\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895938fe",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned details from dineout.co.in and make data frame-\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53164487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Restaurant Name  \\\n",
      "0                   Castle Barbeque   \n",
      "1                        Cafe Knosh   \n",
      "2                 Castle's Barbeque   \n",
      "3                       India Grill   \n",
      "4              The Barbeque Company   \n",
      "5                    Delhi Barbeque   \n",
      "6  The Monarch - Bar Be Que Village   \n",
      "7                 Indian Grill Room   \n",
      "8                The Barbeque Times   \n",
      "\n",
      "                                             Cuisine  \\\n",
      "0       2,000 for 2 (approx) | Chinese, North Indian   \n",
      "1        3,000 for 2 (approx) | Italian, Continental   \n",
      "2       2,000 for 2 (approx) | Chinese, North Indian   \n",
      "3       2,400 for 2 (approx) | North Indian, Italian   \n",
      "4       1,700 for 2 (approx) | North Indian, Chinese   \n",
      "5                1,800 for 2 (approx) | North Indian   \n",
      "6                1,900 for 2 (approx) | North Indian   \n",
      "7       2,200 for 2 (approx) | North Indian, Mughlai   \n",
      "8    1,500 for 2 (approx) | North Indian, Contine...   \n",
      "\n",
      "                                            Location Ratings  \\\n",
      "0                     Connaught Place, Central Delhi       4   \n",
      "1  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
      "2             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
      "3               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
      "4                 Gardens Galleria,Sector 38A, Noida     3.9   \n",
      "5     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
      "6  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
      "7   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
      "8              M2K Corporate Park,Sector 51, Gurgaon     4.1   \n",
      "\n",
      "                                           Image URL  \n",
      "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "8  https://im1.dineout.co.in/images/uploads/resta...  \n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "restaurant_names = []\n",
    "cuisines = []\n",
    "locations = []\n",
    "ratings = []\n",
    "image_urls = []\n",
    "\n",
    "for t1 in soup.find_all(\"a\", class_=\"restnt-name ellipsis\"):\n",
    "    restaurant_names.append(t1.text)\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisines.append(i.text.replace(\"₹\",\" \"))\n",
    "for l1 in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    locations.append(l1.text)\n",
    "for r1 in soup.find_all(\"div\", class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(r1.text)\n",
    "\n",
    "for img in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    image_urls.append(img['data-src'])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'Restaurant Name': restaurant_names,'Cuisine': cuisines,'Location': locations,'Ratings': ratings,'Image URL': image_urls\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f91e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
